{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import amazon_dataset\n",
    "import movielens_dataset\n",
    "import bookcrossing_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_path(dataset: str) -> Path:\n",
    "    if dataset.startswith('ml-'):\n",
    "        return movielens_dataset.BASE_DATA_FOLDER\n",
    "    elif dataset == 'bookcrossing':\n",
    "        return  bookcrossing_dataset.BASE_DATA_FOLDER\n",
    "    return amazon_dataset.BASE_DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET = 'Musical_Instruments'\n",
    "#DATASET = 'Clothing_Shoes_and_Jewelry'\n",
    "#DATASET = 'Home_and_Kitchen'\n",
    "#DATASET = 'Movies_and_TV'\n",
    "DATASET = 'ml-1m'\n",
    "#DATASET = 'bookcrossing'\n",
    "\n",
    "VALIDATION_SIZE=0.15\n",
    "RANDOM_SEED = 20230219\n",
    "MIN_RATING = 0\n",
    "\n",
    "base_path = get_base_path(DATASET)\n",
    "\n",
    "#ALEXNET_IMAGE_FEATURES = BASE_PATH / f'{DATASET}_alexnet_features.npz'\n",
    "VIT_IMAGE_FEATURES = base_path / f'{DATASET}_vit_features.npz'\n",
    "CLIP_IMAGE_FEATURES = base_path / f'{DATASET}_clipimage_features.npz'\n",
    "\n",
    "CLIP_TEXT_FEATURES = base_path / f'{DATASET}_cliptext_features.npz'\n",
    "BERT_TEXT_FEATURES = base_path / f'{DATASET}_bert_features.npz'\n",
    "\n",
    "\n",
    "#assert ALEXNET_IMAGE_FEATURES.exists()\n",
    "assert VIT_IMAGE_FEATURES.exists(), f\"{VIT_IMAGE_FEATURES} does not exist\"\n",
    "assert CLIP_IMAGE_FEATURES.exists(), f\"{CLIP_IMAGE_FEATURES} does not exist\"\n",
    "assert BERT_TEXT_FEATURES.exists(), f\"{BERT_TEXT_FEATURES} does not exist\"\n",
    "assert CLIP_TEXT_FEATURES.exists(), f\"{CLIP_TEXT_FEATURES} does not exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIT features data/movielens/ml-1m_vit_features.npz\n",
      "CLIP Image features data/movielens/ml-1m_clipimage_features.npz\n",
      "BERT Text features data/movielens/ml-1m_bert_features.npz\n",
      "CLIP Text features data/movielens/ml-1m_cliptext_features.npz\n"
     ]
    }
   ],
   "source": [
    "print(f\"VIT features {VIT_IMAGE_FEATURES}\")\n",
    "print(f\"CLIP Image features {CLIP_IMAGE_FEATURES}\")\n",
    "print(f\"BERT Text features {BERT_TEXT_FEATURES}\")\n",
    "print(f\"CLIP Text features {CLIP_TEXT_FEATURES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_ids(series: pd.Series) -> pd.Series:\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    unique_ids = series.unique()\n",
    "    return pd.Series(\n",
    "        index=rng.permutation(unique_ids), \n",
    "        data=range(len(unique_ids))\n",
    "    )\n",
    "\n",
    "def df_stats(df: pd.DataFrame) -> str:\n",
    "    n_items = len(df['item_id'].unique())\n",
    "    n_users = len(df['user_id'].unique())\n",
    "    sparsity = 1. * len(df) / (n_users * n_items)\n",
    "    return f'{n_users} users {n_items} items ratings: {len(df)}. Sparsity {sparsity * 100:.3f}%'\n",
    "\n",
    "def save_numerized(\n",
    "    reviews: pd.DataFrame, \n",
    "    uids: pd.Series, \n",
    "    product_ids: pd.Series,\n",
    "    user_id_column: str,\n",
    "    item_ids_column: str,\n",
    "    columns: List[str],\n",
    "    dest: Path\n",
    "):\n",
    "    \"\"\"Save a Dataframe following userids and product_ids\"\"\"\n",
    "    joined = reviews.join(uids.to_frame(user_id_column), on='user_id')\n",
    "    assert joined[user_id_column].isna().sum() == 0\n",
    "    \n",
    "    joined = joined.join(product_ids.to_frame(item_ids_column), on='item_id')\n",
    "    assert joined[item_ids_column].isna().sum() == 0\n",
    "    \n",
    "    res = joined[columns]\n",
    "    \n",
    "    res.to_csv(dest, index=False)\n",
    "\n",
    "    return res\n",
    "\n",
    "def split_train_test_proportion(df: pd.DataFrame, test_prop=0.2):\n",
    "    \"\"\"\n",
    "    Split the dataframe by reviewer and take exactly `test_prop` records\n",
    "    for test and leave the rest for training\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "    res = df.copy()\n",
    "    res['rnd'] = rng.random(size=len(df))\n",
    "    res['rnd_rank'] = res.groupby('user_id')['rnd'].rank(pct=True)\n",
    "    condition = res['rnd_rank'] <= test_prop\n",
    "    \n",
    "    (_, train), (_, test) = res.groupby(condition)\n",
    "    \n",
    "    assert(len(set(train.index) & set(test.index)) == 0)\n",
    "\n",
    "    return df.loc[train.index], df.loc[test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>759557</th>\n",
       "      <td>4511</td>\n",
       "      <td>2959</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-07-30 17:38:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127663</th>\n",
       "      <td>824</td>\n",
       "      <td>1674</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-11-28 02:15:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216609</th>\n",
       "      <td>1315</td>\n",
       "      <td>858</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-11-21 04:09:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  item_id  rating           timestamp\n",
       "759557     4511     2959       3 2000-07-30 17:38:01\n",
       "127663      824     1674       3 2000-11-28 02:15:46\n",
       "216609     1315      858       5 2000-11-21 04:09:06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_reviews_df(dataset: str, min_rating: int) -> pd.DataFrame:\n",
    "    if dataset.startswith('ml-'):\n",
    "        reviews = movielens_dataset.reviews_df(dataset)\n",
    "    elif dataset == 'bookcrossing':\n",
    "        reviews = bookcrossing_dataset.reviews_df()\n",
    "    else:\n",
    "        reviews = amazon_dataset.reviews_df(dataset)\n",
    "\n",
    "    with_min_ratings = reviews[reviews['rating'] >= min_rating]\n",
    "    # valid user ids\n",
    "    user_id_size = with_min_ratings.groupby('user_id').size()\n",
    "    valid_user_ids = user_id_size.loc[user_id_size >= 5].index\n",
    "    return with_min_ratings[with_min_ratings['user_id'].isin(valid_user_ids)]\n",
    "\n",
    "reviews_df = get_reviews_df(DATASET, min_rating=0)\n",
    "reviews_df.sample(n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for SEM-MacridVAE & DMRL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-1m\n",
      "6040 users 3706 items ratings: 1000209. Sparsity 4.468%\n"
     ]
    }
   ],
   "source": [
    "print(DATASET)\n",
    "print(df_stats(reviews_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort some users randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3853       0\n",
       "1976       1\n",
       "4814       2\n",
       "1517       3\n",
       "4650       4\n",
       "        ... \n",
       "1294    6035\n",
       "644     6036\n",
       "1670    6037\n",
       "2738    6038\n",
       "102     6039\n",
       "Length: 6040, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = generate_unique_ids(reviews_df['user_id'])\n",
    "user_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2845       0\n",
       "2661       1\n",
       "432        2\n",
       "3420       3\n",
       "453        4\n",
       "        ... \n",
       "3142    3701\n",
       "3742    3702\n",
       "1044    3703\n",
       "1945    3704\n",
       "530     3705\n",
       "Length: 3706, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ids = generate_unique_ids(reviews_df['item_id'])\n",
    "item_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train test and validation by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, validation_test_reviews = split_train_test_proportion(reviews_df, test_prop=0.4)\n",
    "validation_reviews, test_reviews = split_train_test_proportion(validation_test_reviews, test_prop=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(validation_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197656"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks. All users are in the train validation and test sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_reviews['user_id']) == set(test_reviews['user_id']) ==  set(validation_reviews['user_id'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the train set and the validation set all have at least one item (same check as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>test_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6040.000000</td>\n",
       "      <td>6040.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.757781</td>\n",
       "      <td>33.115232</td>\n",
       "      <td>32.724503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.651463</td>\n",
       "      <td>38.557939</td>\n",
       "      <td>38.540047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1389.000000</td>\n",
       "      <td>463.000000</td>\n",
       "      <td>462.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_size     val_size    test_size\n",
       "count  6040.000000  6040.000000  6040.000000\n",
       "mean     99.757781    33.115232    32.724503\n",
       "std     115.651463    38.557939    38.540047\n",
       "min      12.000000     4.000000     4.000000\n",
       "25%      27.000000     9.000000     8.000000\n",
       "50%      58.000000    19.000000    19.000000\n",
       "75%     125.000000    42.000000    41.000000\n",
       "max    1389.000000   463.000000   462.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    train_reviews.groupby('user_id').size().to_frame('train_size'),\n",
    "    validation_reviews.groupby('user_id').size().to_frame('val_size'),\n",
    "    test_reviews.groupby('user_id').size().to_frame('test_size')\n",
    "], axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>text</th>\n",
       "      <th>image_features</th>\n",
       "      <th>text_features</th>\n",
       "      <th>dest_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vit</td>\n",
       "      <td>bert</td>\n",
       "      <td>data/movielens/ml-1m_vit_features.npz</td>\n",
       "      <td>data/movielens/ml-1m_bert_features.npz</td>\n",
       "      <td>data/ml-1m-vit_bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>none</td>\n",
       "      <td>bert</td>\n",
       "      <td>None</td>\n",
       "      <td>data/movielens/ml-1m_bert_features.npz</td>\n",
       "      <td>data/ml-1m-none_bert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vit</td>\n",
       "      <td>none</td>\n",
       "      <td>data/movielens/ml-1m_vit_features.npz</td>\n",
       "      <td>None</td>\n",
       "      <td>data/ml-1m-vit_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip</td>\n",
       "      <td>clip</td>\n",
       "      <td>data/movielens/ml-1m_clipimage_features.npz</td>\n",
       "      <td>data/movielens/ml-1m_cliptext_features.npz</td>\n",
       "      <td>data/ml-1m-clip_clip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>none</td>\n",
       "      <td>clip</td>\n",
       "      <td>None</td>\n",
       "      <td>data/movielens/ml-1m_cliptext_features.npz</td>\n",
       "      <td>data/ml-1m-none_clip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>clip</td>\n",
       "      <td>none</td>\n",
       "      <td>data/movielens/ml-1m_clipimage_features.npz</td>\n",
       "      <td>None</td>\n",
       "      <td>data/ml-1m-clip_none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>data/ml-1m-none_none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image  text                               image_features  \\\n",
       "0   vit  bert        data/movielens/ml-1m_vit_features.npz   \n",
       "1  none  bert                                         None   \n",
       "2   vit  none        data/movielens/ml-1m_vit_features.npz   \n",
       "3  clip  clip  data/movielens/ml-1m_clipimage_features.npz   \n",
       "4  none  clip                                         None   \n",
       "5  clip  none  data/movielens/ml-1m_clipimage_features.npz   \n",
       "6  none  none                                         None   \n",
       "\n",
       "                                text_features           dest_folder  \n",
       "0      data/movielens/ml-1m_bert_features.npz   data/ml-1m-vit_bert  \n",
       "1      data/movielens/ml-1m_bert_features.npz  data/ml-1m-none_bert  \n",
       "2                                        None   data/ml-1m-vit_none  \n",
       "3  data/movielens/ml-1m_cliptext_features.npz  data/ml-1m-clip_clip  \n",
       "4  data/movielens/ml-1m_cliptext_features.npz  data/ml-1m-none_clip  \n",
       "5                                        None  data/ml-1m-clip_none  \n",
       "6                                        None  data/ml-1m-none_none  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations = pd.DataFrame.from_records([\n",
    "    ('vit', 'bert', VIT_IMAGE_FEATURES, BERT_TEXT_FEATURES),\n",
    "    ('none', 'bert', None, BERT_TEXT_FEATURES),\n",
    "    ('vit', 'none', VIT_IMAGE_FEATURES, None),\n",
    "    ('clip', 'clip', CLIP_IMAGE_FEATURES, CLIP_TEXT_FEATURES),\n",
    "    ('none', 'clip', None, CLIP_TEXT_FEATURES),\n",
    "    ('clip', 'none', CLIP_IMAGE_FEATURES, None),\n",
    "    ('none', 'none', None, None),\n",
    "], columns=['image', 'text', 'image_features', 'text_features'])\n",
    "combinations['dest_folder'] = combinations.apply(\n",
    "    lambda x: Path(f'data/{DATASET}-{x[\"image\"]}_{x[\"text\"]}'), axis=1\n",
    ")\n",
    "combinations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in combinations.itertuples():\n",
    "    c.dest_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    user_ids.to_csv(c.dest_folder / 'users.txt')\n",
    "    item_ids.to_csv(c.dest_folder / 'items.txt', header=['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIZED_COMMON_PARAMS = {\n",
    "    'uids': user_ids, \n",
    "    'product_ids': item_ids,\n",
    "    'user_id_column': 'user',\n",
    "    'item_ids_column': 'item',\n",
    "    'columns': ['user', 'item']\n",
    "}\n",
    "\n",
    "for c in combinations.itertuples():\n",
    "    c.dest_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    save_numerized(\n",
    "        train_reviews, \n",
    "        dest=c.dest_folder / 'train.txt',\n",
    "        **NUMERIZED_COMMON_PARAMS\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved validation data'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in combinations.itertuples():\n",
    "    c.dest_folder.mkdir(exist_ok=True)\n",
    "\n",
    "    save_numerized(\n",
    "        validation_reviews, \n",
    "        dest=c.dest_folder / 'validation.txt',\n",
    "        **NUMERIZED_COMMON_PARAMS\n",
    "    )\n",
    "\n",
    "\n",
    "'Saved validation data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved test data'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in combinations.itertuples():\n",
    "    save_numerized(\n",
    "        test_reviews, \n",
    "        dest=c.dest_folder / 'test.txt',\n",
    "        **NUMERIZED_COMMON_PARAMS\n",
    "    )\n",
    "'Saved test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=0, image='vit', text='bert', image_features=PosixPath('data/movielens/ml-1m_vit_features.npz'), text_features=PosixPath('data/movielens/ml-1m_bert_features.npz'), dest_folder=PosixPath('data/ml-1m-vit_bert'))\n",
      "Opening file data/movielens/ml-1m_vit_features.npz\n",
      "Initializing array (3706, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features:   0%|          | 0.00/3.71k [00:00<?, ?items/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 3.71k/3.71k [00:01<00:00, 2.29kitems/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ml-1m-vit_bert/embed_image.npy: 28MiB\n",
      "Pandas(Index=1, image='none', text='bert', image_features=None, text_features=PosixPath('data/movielens/ml-1m_bert_features.npz'), dest_folder=PosixPath('data/ml-1m-none_bert'))\n",
      "Returning Zeros\n",
      "data/ml-1m-none_bert/embed_image.npy: 3MiB\n",
      "Pandas(Index=2, image='vit', text='none', image_features=PosixPath('data/movielens/ml-1m_vit_features.npz'), text_features=None, dest_folder=PosixPath('data/ml-1m-vit_none'))\n",
      "data/ml-1m-vit_none/embed_image.npy: 28MiB\n",
      "Pandas(Index=3, image='clip', text='clip', image_features=PosixPath('data/movielens/ml-1m_clipimage_features.npz'), text_features=PosixPath('data/movielens/ml-1m_cliptext_features.npz'), dest_folder=PosixPath('data/ml-1m-clip_clip'))\n",
      "Opening file data/movielens/ml-1m_clipimage_features.npz\n",
      "Initializing array (3706, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 3.71k/3.71k [00:01<00:00, 2.50kitems/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ml-1m-clip_clip/embed_image.npy: 21MiB\n",
      "Pandas(Index=4, image='none', text='clip', image_features=None, text_features=PosixPath('data/movielens/ml-1m_cliptext_features.npz'), dest_folder=PosixPath('data/ml-1m-none_clip'))\n",
      "data/ml-1m-none_clip/embed_image.npy: 3MiB\n",
      "Pandas(Index=5, image='clip', text='none', image_features=PosixPath('data/movielens/ml-1m_clipimage_features.npz'), text_features=None, dest_folder=PosixPath('data/ml-1m-clip_none'))\n",
      "data/ml-1m-clip_none/embed_image.npy: 21MiB\n",
      "Pandas(Index=6, image='none', text='none', image_features=None, text_features=None, dest_folder=PosixPath('data/ml-1m-none_none'))\n",
      "data/ml-1m-none_none/embed_image.npy: 3MiB\n"
     ]
    }
   ],
   "source": [
    "@lru_cache()\n",
    "def copy_features(features_file: Optional[Path]):\n",
    "    if features_file is None:\n",
    "        print('Returning Zeros')\n",
    "        return np.zeros((len(item_ids), 256), dtype=np.float32)\n",
    "\n",
    "    print(f'Opening file {features_file}')\n",
    "    with np.load(features_file) as features:\n",
    "        some_embedding = next(iter(features.values()))\n",
    "        embedding_shape, = some_embedding.shape\n",
    "        array_shape = (len(item_ids),  embedding_shape)\n",
    "        print(f'Initializing array {array_shape}')\n",
    "        res = np.full(array_shape,  fill_value=np.nan)\n",
    "\n",
    "        for item_id, idx in tqdm(item_ids.items(), \n",
    "                total=len(item_ids), unit_scale=True, unit='items', \n",
    "                desc='Copying features'):\n",
    "            value = features.get(str(item_id))\n",
    "            if value is None:\n",
    "                print(f'Item {item_id} not found in features file')\n",
    "                res[idx, :] = 0    \n",
    "            else:\n",
    "                assert np.isnan(value).sum() == 0, \"Feature has NaN Values\"\n",
    "                res[idx, :] = value\n",
    "\n",
    "        return res\n",
    "\n",
    "for c in combinations.itertuples():\n",
    "    print(c)\n",
    "    features_array = copy_features(features_file=c.image_features)\n",
    "    embed_dest = c.dest_folder / 'embed_image.npy'\n",
    "    np.save(embed_dest, features_array)\n",
    "\n",
    "    print(f'{str(embed_dest)}: {embed_dest.stat().st_size // 2**20}MiB')\n",
    "\n",
    "copy_features.cache_clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas(Index=0, image='vit', text='bert', image_features=PosixPath('data/movielens/ml-1m_vit_features.npz'), text_features=PosixPath('data/movielens/ml-1m_bert_features.npz'), dest_folder=PosixPath('data/ml-1m-vit_bert'))\n",
      "Opening file data/movielens/ml-1m_bert_features.npz\n",
      "Initializing array (3706, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 3.71k/3.71k [00:01<00:00, 2.41kitems/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ml-1m-vit_bert/embed_text.npy: 28MiB\n",
      "Pandas(Index=1, image='none', text='bert', image_features=None, text_features=PosixPath('data/movielens/ml-1m_bert_features.npz'), dest_folder=PosixPath('data/ml-1m-none_bert'))\n",
      "data/ml-1m-none_bert/embed_text.npy: 28MiB\n",
      "Pandas(Index=2, image='vit', text='none', image_features=PosixPath('data/movielens/ml-1m_vit_features.npz'), text_features=None, dest_folder=PosixPath('data/ml-1m-vit_none'))\n",
      "Returning Zeros\n",
      "data/ml-1m-vit_none/embed_text.npy: 3MiB\n",
      "Pandas(Index=3, image='clip', text='clip', image_features=PosixPath('data/movielens/ml-1m_clipimage_features.npz'), text_features=PosixPath('data/movielens/ml-1m_cliptext_features.npz'), dest_folder=PosixPath('data/ml-1m-clip_clip'))\n",
      "Opening file data/movielens/ml-1m_cliptext_features.npz\n",
      "Initializing array (3706, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 3.71k/3.71k [00:01<00:00, 2.46kitems/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/ml-1m-clip_clip/embed_text.npy: 21MiB\n",
      "Pandas(Index=4, image='none', text='clip', image_features=None, text_features=PosixPath('data/movielens/ml-1m_cliptext_features.npz'), dest_folder=PosixPath('data/ml-1m-none_clip'))\n",
      "data/ml-1m-none_clip/embed_text.npy: 21MiB\n",
      "Pandas(Index=5, image='clip', text='none', image_features=PosixPath('data/movielens/ml-1m_clipimage_features.npz'), text_features=None, dest_folder=PosixPath('data/ml-1m-clip_none'))\n",
      "data/ml-1m-clip_none/embed_text.npy: 3MiB\n",
      "Pandas(Index=6, image='none', text='none', image_features=None, text_features=None, dest_folder=PosixPath('data/ml-1m-none_none'))\n",
      "data/ml-1m-none_none/embed_text.npy: 3MiB\n"
     ]
    }
   ],
   "source": [
    "for c in combinations.itertuples():\n",
    "    print(c)\n",
    "    features_array = copy_features(features_file=c.text_features)\n",
    "    embed_dest = c.dest_folder / 'embed_text.npy'\n",
    "    np.save(embed_dest, features_array)\n",
    "\n",
    "    print(f'{str(embed_dest)}: {embed_dest.stat().st_size // 2**20}MiB')\n",
    "\n",
    "copy_features.cache_clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c22d1444aa3f68a820bd00264b529de9aca8b813336c5d71bda95dadce90fbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
