{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import amazon_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATASET = 'Musical_Instruments'\n",
    "#DATASET = 'Clothing_Shoes_and_Jewelry'\n",
    "#DATASET = 'Home_and_Kitchen'\n",
    "DATASET = 'Movies_and_TV'\n",
    "\n",
    "VALIDATION_SIZE=0.15\n",
    "RANDOM_SEED = 20230219\n",
    "#ALEXNET_IMAGE_FEATURES = Path(f'data/amazon/{DATASET}_alexnet_features.npz')\n",
    "VIT_IMAGE_FEATURES = Path(f'data/amazon/{DATASET}_vit_features.npz')\n",
    "CLIP_IMAGE_FEATURES = Path(f'data/amazon/{DATASET}_clipimage_features.npz')\n",
    "\n",
    "CLIP_TEXT_FEATURES = Path(f'data/amazon/{DATASET}_cliptext_features.npz')\n",
    "BERT_TEXT_FEATURES = Path(f'data/amazon/{DATASET}_bert_features.npz')\n",
    "DEST_FOLDER = Path(f'data/{DATASET}')\n",
    "\n",
    "#assert ALEXNET_IMAGE_FEATURES.exists()\n",
    "assert VIT_IMAGE_FEATURES.exists(), f\"{VIT_IMAGE_FEATURES} does not exist\"\n",
    "assert CLIP_IMAGE_FEATURES.exists(), f\"{CLIP_IMAGE_FEATURES} does not exist\"\n",
    "assert BERT_TEXT_FEATURES.exists(), f\"{BERT_TEXT_FEATURES} does not exist\"\n",
    "assert CLIP_TEXT_FEATURES.exists(), f\"{CLIP_TEXT_FEATURES} does not exist\"\n",
    "\n",
    "image_features = CLIP_IMAGE_FEATURES\n",
    "text_featues = CLIP_TEXT_FEATURES\n",
    "\n",
    "DEST_FOLDER.mkdir(exist_ok=True)\n",
    "\n",
    "with open(DEST_FOLDER / 'signature.txt', mode='w') as f:\n",
    "    f.write(f'Image: {image_features.stem}\\nText: {text_featues.stem}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_ids(series: pd.Series) -> pd.Series:\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    unique_ids = series.unique()\n",
    "    return pd.Series(\n",
    "        index=rng.permutation(unique_ids), \n",
    "        data=range(len(unique_ids))\n",
    "    )\n",
    "\n",
    "def df_stats(df: pd.DataFrame) -> str:\n",
    "    n_items = len(df['asin'].unique())\n",
    "    n_users = len(df['reviewerID'].unique())\n",
    "    sparsity = 1. * len(df) / (n_users * n_items)\n",
    "    return f'{n_users} users {n_items} items ratings: {len(df)}. Sparsity {sparsity * 100:.3f}%'\n",
    "\n",
    "def save_numerized(\n",
    "    reviews: pd.DataFrame, \n",
    "    uids: pd.Series, \n",
    "    product_ids: pd.Series,\n",
    "    user_id_column: str,\n",
    "    product_ids_column: str,\n",
    "    columns: List[str],\n",
    "    dest: Path\n",
    "):\n",
    "    \"\"\"Save a Dataframe following userids and product_ids\"\"\"\n",
    "    joined = reviews.join(uids.to_frame(user_id_column), on='reviewerID')\n",
    "    assert joined[user_id_column].isna().sum() == 0\n",
    "    \n",
    "    joined = joined.join(product_ids.to_frame(product_ids_column), on='asin')\n",
    "    assert joined[product_ids_column].isna().sum() == 0\n",
    "    \n",
    "    res = joined[columns]\n",
    "    \n",
    "    res.to_csv(dest, index=False)\n",
    "\n",
    "    return res\n",
    "\n",
    "def split_train_test_proportion(df: pd.DataFrame, test_prop=0.2):\n",
    "    \"\"\"\n",
    "    Split the dataframe by reviewer and take exactly `test_prop` records\n",
    "    for test and leave the rest for training\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "    res = df.copy()\n",
    "    res['rnd'] = rng.random(size=len(df))\n",
    "    res['rnd_rank'] = res.groupby('reviewerID')['rnd'].rank(pct=True)\n",
    "    condition = res['rnd_rank'] <= test_prop\n",
    "    \n",
    "    (_, train), (_, test) = res.groupby(condition)\n",
    "    \n",
    "    assert(len(set(train.index) & set(test.index)) == 0)\n",
    "\n",
    "    return df.loc[train.index], df.loc[test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>text</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34892</th>\n",
       "      <td>12905960</td>\n",
       "      <td>B00TFYLR0Y</td>\n",
       "      <td>AKHDFQ79K5O4X</td>\n",
       "      <td>Alicia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I am 5'4\", 150 lbs, and this \"towel\" is more l...</td>\n",
       "      <td>2018-04-20</td>\n",
       "      <td>Amazing, just buy one!</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75339</th>\n",
       "      <td>19037414</td>\n",
       "      <td>B00C7WEAAK</td>\n",
       "      <td>A1953DM9YJ6IYZ</td>\n",
       "      <td>J. Reynolds</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is beyond cool. We were the hit of the ne...</td>\n",
       "      <td>2018-03-26</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59405</th>\n",
       "      <td>16556205</td>\n",
       "      <td>B01ES3LDGO</td>\n",
       "      <td>A3C6600HT8BFUN</td>\n",
       "      <td>T. Cotton</td>\n",
       "      <td>3.0</td>\n",
       "      <td>The fitted sheet is not persimmon... it's oran...</td>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>The fitted sheet is not persimmon... it's orange</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id        asin      reviewerID reviewerName  overall  \\\n",
       "34892  12905960  B00TFYLR0Y   AKHDFQ79K5O4X       Alicia      5.0   \n",
       "75339  19037414  B00C7WEAAK  A1953DM9YJ6IYZ  J. Reynolds      5.0   \n",
       "59405  16556205  B01ES3LDGO  A3C6600HT8BFUN    T. Cotton      3.0   \n",
       "\n",
       "                                                    text  reviewTime  \\\n",
       "34892  I am 5'4\", 150 lbs, and this \"towel\" is more l...  2018-04-20   \n",
       "75339  This is beyond cool. We were the hit of the ne...  2018-03-26   \n",
       "59405  The fitted sheet is not persimmon... it's oran...  2018-08-27   \n",
       "\n",
       "                                                summary  verified  vote  \n",
       "34892                            Amazing, just buy one!      True   NaN  \n",
       "75339                                        Five Stars      True   NaN  \n",
       "59405  The fitted sheet is not persimmon... it's orange      True   NaN  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = amazon_dataset.reviews_df(DATASET)\n",
    "reviews_df.sample(n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for SEM-MacridVAE & DMRL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home_and_Kitchen\n",
      "14429 users 29040 items ratings: 93923. Sparsity 0.022%\n"
     ]
    }
   ],
   "source": [
    "print(DATASET)\n",
    "print(df_stats(reviews_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort some users randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A18ISN6NS073V2       0\n",
       "A1XFJTXA00NYX1       1\n",
       "A3GITGRRVQ4IP0       2\n",
       "A1W2V8Z9EWTZMM       3\n",
       "AEOQG6GFYR009        4\n",
       "                  ... \n",
       "A2LSUIA9THHK57    5417\n",
       "A31D3XL44W1NBM    5418\n",
       "A3775OP5VTX5ON    5419\n",
       "A1G0HYMR02WM2W    5420\n",
       "A7CN7OR0X715S     5421\n",
       "Length: 5422, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = generate_unique_ids(reviews_df['reviewerID'])\n",
    "user_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B0002GXZK4       0\n",
       "B00ZUBQY9K       1\n",
       "B00VUU6JL8       2\n",
       "B00PUQK4FU       3\n",
       "B00UTUKFHE       4\n",
       "              ... \n",
       "B000EEJ8VE    8455\n",
       "B00CAL9ZXK    8456\n",
       "B00U1XK5Z6    8457\n",
       "B0002D0CNA    8458\n",
       "B016L4MRMW    8459\n",
       "Length: 8460, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ids = generate_unique_ids(reviews_df['asin'])\n",
    "item_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train test and validation by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, validation_test_reviews = split_train_test_proportion(reviews_df, test_prop=0.4)\n",
    "validation_reviews, test_reviews = split_train_test_proportion(validation_test_reviews, test_prop=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25628"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(validation_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6744"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks. All users are in the train validation and test sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_reviews['reviewerID']) == set(test_reviews['reviewerID']) ==  set(validation_reviews['reviewerID'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the train set and the validation set all have at least one item (same check as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>test_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5422.000000</td>\n",
       "      <td>5422.000000</td>\n",
       "      <td>5422.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.726669</td>\n",
       "      <td>1.428624</td>\n",
       "      <td>1.243821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.451181</td>\n",
       "      <td>0.840090</td>\n",
       "      <td>0.720182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_size     val_size    test_size\n",
       "count  5422.000000  5422.000000  5422.000000\n",
       "mean      4.726669     1.428624     1.243821\n",
       "std       2.451181     0.840090     0.720182\n",
       "min       3.000000     1.000000     1.000000\n",
       "25%       3.000000     1.000000     1.000000\n",
       "50%       4.000000     1.000000     1.000000\n",
       "75%       5.000000     2.000000     1.000000\n",
       "max      36.000000    12.000000    12.000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    train_reviews.groupby('reviewerID').size().to_frame('train_size'),\n",
    "    validation_reviews.groupby('reviewerID').size().to_frame('val_size'),\n",
    "    test_reviews.groupby('reviewerID').size().to_frame('test_size')\n",
    "], axis=1).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids.to_csv(DEST_FOLDER / 'users.txt')\n",
    "item_ids.to_csv(DEST_FOLDER / 'items.txt', header=['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4486</td>\n",
       "      <td>7218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>973</td>\n",
       "      <td>4137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>262</td>\n",
       "      <td>8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3690</td>\n",
       "      <td>8243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4550</td>\n",
       "      <td>1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40111</th>\n",
       "      <td>3812</td>\n",
       "      <td>5551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40114</th>\n",
       "      <td>1767</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40115</th>\n",
       "      <td>2735</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40116</th>\n",
       "      <td>3161</td>\n",
       "      <td>5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40117</th>\n",
       "      <td>4142</td>\n",
       "      <td>5364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25628 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item\n",
       "0      4486  7218\n",
       "4       973  4137\n",
       "5       262  8243\n",
       "6      3690  8243\n",
       "10     4550  1665\n",
       "...     ...   ...\n",
       "40111  3812  5551\n",
       "40114  1767    53\n",
       "40115  2735    53\n",
       "40116  3161  5364\n",
       "40117  4142  5364\n",
       "\n",
       "[25628 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERIZED_COMMON_PARAMS = {\n",
    "    'uids': user_ids, \n",
    "    'product_ids': item_ids,\n",
    "    'user_id_column': 'user',\n",
    "    'product_ids_column': 'item',\n",
    "    'columns': ['user', 'item']\n",
    "}\n",
    "\n",
    "save_numerized(\n",
    "    train_reviews, \n",
    "    dest=DEST_FOLDER / 'train.txt',\n",
    "    **NUMERIZED_COMMON_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved validation data'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_numerized(\n",
    "    validation_reviews, \n",
    "    dest=DEST_FOLDER / 'validation.txt',\n",
    "    **NUMERIZED_COMMON_PARAMS\n",
    ")\n",
    "'Saved validation data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved test data'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_numerized(\n",
    "    test_reviews, \n",
    "    dest=DEST_FOLDER / 'test.txt',\n",
    "    **NUMERIZED_COMMON_PARAMS\n",
    ")\n",
    "'Saved test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file\n",
      "Initializing array (8460, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 8.46k/8.46k [00:04<00:00, 2.00kitems/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8460, 768)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def copy_features(\n",
    "        item_ids: pd.Series, \n",
    "        features_file: Path\n",
    "):\n",
    "    print('Opening file')\n",
    "    with np.load(features_file) as features:\n",
    "        some_embedding = next(iter(features.values()))\n",
    "        embedding_shape, = some_embedding.shape\n",
    "        array_shape = (len(item_ids),  embedding_shape)\n",
    "        print(f'Initializing array {array_shape}')\n",
    "        res = np.full(array_shape,  fill_value=np.nan)\n",
    "\n",
    "        for asin, idx in tqdm(item_ids.items(), \n",
    "                total=len(item_ids), unit_scale=True, unit='items', \n",
    "                desc='Copying features'):\n",
    "            value = features.get(asin)\n",
    "            if value is None:\n",
    "                print(f'Item {asin} not found in features file')\n",
    "                res[idx, :] = 0    \n",
    "            else:\n",
    "                assert np.isnan(value).sum() == 0, \"Feature has NaN Values\"\n",
    "                res[idx, :] = value\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "image_features_array = copy_features(\n",
    "    item_ids=item_ids, \n",
    "    features_file=image_features\n",
    ")\n",
    "image_features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Musical_Instruments/embed_image.npy: 49MiB\n"
     ]
    }
   ],
   "source": [
    "IMAGE_EMBED_DEST = DEST_FOLDER / 'embed_image.npy'\n",
    "np.save(IMAGE_EMBED_DEST, image_features_array)\n",
    "\n",
    "print(f'{str(IMAGE_EMBED_DEST)}: {IMAGE_EMBED_DEST.stat().st_size // 2**20}MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file\n",
      "Initializing array (8460, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 8.46k/8.46k [00:04<00:00, 1.97kitems/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8460, 768)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_array = copy_features(\n",
    "    item_ids=item_ids, \n",
    "    features_file=text_featues\n",
    ")\n",
    "text_features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Musical_Instruments/embed_text.npy: 49MiB\n"
     ]
    }
   ],
   "source": [
    "TEXT_EMBED_DEST = DEST_FOLDER / 'embed_text.npy'\n",
    "np.save(TEXT_EMBED_DEST, text_features_array)\n",
    "\n",
    "print(f'{str(TEXT_EMBED_DEST)}: {TEXT_EMBED_DEST.stat().st_size // 2**20}MiB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/amazon/Musical_Instruments_product_images')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df = amazon_dataset.products_df(DATASET)\n",
    "products_images_dir = amazon_dataset.product_images_dir(DATASET)\n",
    "products_images_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is necessary only for generating the fancy graph. Puts images on an transparent background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def convert_image(src: str, dst: str):\n",
    "    min_white = np.array([235, 235, 235], np.uint8)\n",
    "    white = np.array([255, 255, 255], np.uint8)\n",
    "    img = cv2.imread(src)\n",
    "    \n",
    "    mask = 255 - cv2.inRange(img, min_white, white)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "    res = cv2.bitwise_and(img, img, mask=mask)\n",
    "    cv2.imwrite(dst, res)\n",
    "\n",
    "def save_images(products_df: pd.DataFrame, item_ids: pd.Series, dest: Path):\n",
    "    products_by_asin = products_df.set_index('asin')\n",
    "    joined  = item_ids.to_frame('item_id').join(\n",
    "        products_by_asin, validate='one_to_one'\n",
    "    )\n",
    "    dest.mkdir(exist_ok=True)\n",
    "    \n",
    "    no_images = 0\n",
    "    \n",
    "    progress = tqdm(\n",
    "        joined.itertuples(), \n",
    "        desc='Copying images', \n",
    "        total=len(joined), \n",
    "        unit_scale=True, unit='items'\n",
    "    )\n",
    "    for row in progress:\n",
    "        if not isinstance(row.image_slug, list):\n",
    "            print('Not a list')\n",
    "            break\n",
    "        if len(row.image_slug) == 0:\n",
    "            no_images += 1\n",
    "            progress.set_postfix_str(f'No images: {no_images}', refresh=False)\n",
    "            continue\n",
    "        slug = row.image_slug[0]\n",
    "        src = products_images_dir / f\"{slug}.jpg\"\n",
    "        assert src.exists()\n",
    "        dst = dest / f'{row.item_id}.png'\n",
    "        convert_image(str(src), str(dst))\n",
    "\n",
    "#save_images(products_df, item_ids,  DEST_FOLDER / 'images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_df = amazon_dataset.product_categories_df(DATASET)\n",
    "# products_df = amazon_dataset.products_df(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_id = generate_unique_ids(categories_df['name'])\n",
    "# categories_id.to_csv(DEST_FOLDER / 'categories.txt', header=['category_id'])\n",
    "# categories_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_categories_matrix(\n",
    "        categories_df: pd.DataFrame, \n",
    "        products_df: pd.DataFrame, \n",
    "        item_ids: pd.Series, \n",
    "        categories_id: pd.Series\n",
    "    ):\n",
    "    MIN_SUPPORT = 0.01\n",
    "    MAX_SUPPORT = 0.9\n",
    "    \n",
    "    # Categories only with not too many or too few items\n",
    "    categories_support = categories_df['name'].value_counts() \n",
    "\n",
    "    allowed_categories_names = categories_support[1:8].index\n",
    "\n",
    "    print(\"How many allowed categories\")\n",
    "    print(len(allowed_categories_names))\n",
    "    print(allowed_categories_names)\n",
    "    \n",
    "    filtered_categories = categories_df.loc[\n",
    "        categories_df['name'].isin(allowed_categories_names)\n",
    "    ]\n",
    "\n",
    "    products_df = products_df.join(\n",
    "        item_ids.to_frame('item_id'), on='asin', validate='1:1')\n",
    "\n",
    "    res = filtered_categories.set_index('product_id').join(\n",
    "        products_df, validate='m:1')\n",
    "    res = res.reset_index(drop=True)\n",
    "    \n",
    "    # Check all categories are in categories_id\n",
    "    res = res.join(categories_id.to_frame('category_id'), on='name')\n",
    "    assert res['category_id'].isna().sum() == 0\n",
    "\n",
    "    items_with_no_category = set(item_ids) - set(res['item_id'].unique())\n",
    "    print(f\"items with no category: {len(items_with_no_category)}\")\n",
    "    \n",
    "    return products_df.loc[\n",
    "        products_df['asin'].isin(item_ids[items_with_no_category].index)\n",
    "    ]\n",
    "\n",
    "    return res[['item_id', 'category_id']]\n",
    "\n",
    "# categories_matrix = build_categories_matrix(\n",
    "#     categories_df, products_df, item_ids, categories_id\n",
    "# )\n",
    "#categories_matrix\n",
    "#categories_matrix.to_csv(DEST_FOLDER / 'categorical.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c22d1444aa3f68a820bd00264b529de9aca8b813336c5d71bda95dadce90fbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
