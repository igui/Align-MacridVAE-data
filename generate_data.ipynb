{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import amazon_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m BERT_TEXT_FEATURES \u001b[39m=\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/amazon/\u001b[39m\u001b[39m{\u001b[39;00mDATASET\u001b[39m}\u001b[39;00m\u001b[39m_bert_features.npz\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m DEST_FOLDER \u001b[39m=\u001b[39m Path(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata/\u001b[39m\u001b[39m{\u001b[39;00mDATASET\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[39massert\u001b[39;00m ALEXNET_IMAGE_FEATURES\u001b[39m.\u001b[39mexists()\n\u001b[1;32m     13\u001b[0m \u001b[39massert\u001b[39;00m VIT_IMAGE_FEATURES\u001b[39m.\u001b[39mexists()\n\u001b[1;32m     14\u001b[0m \u001b[39massert\u001b[39;00m CLIP_IMAGE_FEATURES\u001b[39m.\u001b[39mexists()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET = 'Home_and_Kitchen'\n",
    "VALIDATION_SIZE=0.15\n",
    "RANDOM_SEED = 20230219\n",
    "ALEXNET_IMAGE_FEATURES = Path(f'data/amazon/{DATASET}_alexnet_features.npz')\n",
    "VIT_IMAGE_FEATURES = Path(f'data/amazon/{DATASET}_vit_features.npz')\n",
    "CLIP_IMAGE_FEATURES = Path(f'data/amazon/{DATASET}_clipimage_features.npz')\n",
    "\n",
    "CLIP_TEXT_FEATURES = Path(f'data/amazon/{DATASET}_cliptext_features.npz')\n",
    "BERT_TEXT_FEATURES = Path(f'data/amazon/{DATASET}_bert_features.npz')\n",
    "DEST_FOLDER = Path(f'data/{DATASET}')\n",
    "\n",
    "assert ALEXNET_IMAGE_FEATURES.exists()\n",
    "assert VIT_IMAGE_FEATURES.exists()\n",
    "assert CLIP_IMAGE_FEATURES.exists()\n",
    "\n",
    "assert BERT_TEXT_FEATURES.exists()\n",
    "assert CLIP_TEXT_FEATURES.exists()\n",
    "\n",
    "\n",
    "DEST_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_ids(series: pd.Series) -> pd.Series:\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    unique_ids = series.unique()\n",
    "    return pd.Series(\n",
    "        index=rng.permutation(unique_ids), \n",
    "        data=range(len(unique_ids))\n",
    "    )\n",
    "\n",
    "def df_stats(df: pd.DataFrame) -> str:\n",
    "    n_items = len(df['asin'].unique())\n",
    "    n_users = len(df['reviewerID'].unique())\n",
    "    sparsity = 1. * len(df) / (n_users * n_items)\n",
    "    return f'{n_items} items {n_users} users. Sparsity {sparsity * 100:.3f}%'\n",
    "\n",
    "def save_numerized(\n",
    "    reviews: pd.DataFrame, \n",
    "    uids: pd.Series, \n",
    "    product_ids: pd.Series,\n",
    "    user_id_column: str,\n",
    "    product_ids_column: str,\n",
    "    columns: List[str],\n",
    "    dest: Path\n",
    "):\n",
    "    \"\"\"Save a Dataframe following userids and product_ids\"\"\"\n",
    "    joined = reviews.join(uids.to_frame(user_id_column), on='reviewerID')\n",
    "    assert joined[user_id_column].isna().sum() == 0\n",
    "    \n",
    "    joined = joined.join(product_ids.to_frame(product_ids_column), on='asin')\n",
    "    assert joined[product_ids_column].isna().sum() == 0\n",
    "    \n",
    "    res = joined[columns]\n",
    "    \n",
    "    res.to_csv(dest, index=False)\n",
    "\n",
    "    return res\n",
    "\n",
    "def split_train_test_proportion(df: pd.DataFrame, test_prop=0.2):\n",
    "    \"\"\"\n",
    "    Split the dataframe by reviewer and take exactly `test_prop` records\n",
    "    for test and leave the rest for training\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "    res = df.copy()\n",
    "    res['rnd'] = rng.random(size=len(df))\n",
    "    res['rnd_rank'] = res.groupby('reviewerID')['rnd'].rank(pct=True)\n",
    "    condition = res['rnd_rank'] <= test_prop\n",
    "    \n",
    "    (_, train), (_, test) = res.groupby(condition)\n",
    "    \n",
    "    assert(len(set(train.index) & set(test.index)) == 0)\n",
    "\n",
    "    return df.loc[train.index], df.loc[test.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>text</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139502</th>\n",
       "      <td>22958616</td>\n",
       "      <td>B000XBM1L2</td>\n",
       "      <td>A1IRP8WERRLVGR</td>\n",
       "      <td>louie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My grandson they fit fine.  Could have been a ...</td>\n",
       "      <td>2018-05-23</td>\n",
       "      <td>My grandson they fit fine. Could have been a l...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42897</th>\n",
       "      <td>9047159</td>\n",
       "      <td>B00AFQZT4Q</td>\n",
       "      <td>A1WHGWRWCH8QAQ</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>5.0</td>\n",
       "      <td>These are a little tiny bit large, but are so ...</td>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>Nice shoes</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73132</th>\n",
       "      <td>16379375</td>\n",
       "      <td>B00SU5244M</td>\n",
       "      <td>AJ2J83VRCIHYR</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>They're great. Dated a guy recently who had al...</td>\n",
       "      <td>2018-03-28</td>\n",
       "      <td>They're great. Dated a guy recently who had al...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id        asin      reviewerID     reviewerName  overall  \\\n",
       "139502  22958616  B000XBM1L2  A1IRP8WERRLVGR            louie      5.0   \n",
       "42897    9047159  B00AFQZT4Q  A1WHGWRWCH8QAQ        Anonymous      5.0   \n",
       "73132   16379375  B00SU5244M   AJ2J83VRCIHYR  Amazon Customer      5.0   \n",
       "\n",
       "                                                     text  reviewTime  \\\n",
       "139502  My grandson they fit fine.  Could have been a ...  2018-05-23   \n",
       "42897   These are a little tiny bit large, but are so ...  2018-04-06   \n",
       "73132   They're great. Dated a guy recently who had al...  2018-03-28   \n",
       "\n",
       "                                                  summary  verified  vote  \n",
       "139502  My grandson they fit fine. Could have been a l...      True   NaN  \n",
       "42897                                          Nice shoes      True   NaN  \n",
       "73132   They're great. Dated a guy recently who had al...      True   NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = amazon_dataset.reviews_df(DATASET)\n",
    "reviews_df.sample(n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for SEM-MacridVAE & DMRL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38493 items 23318 users. Sparsity 0.020%\n"
     ]
    }
   ],
   "source": [
    "print(df_stats(reviews_df))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort some users randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A30NKRF3KBGA06        0\n",
       "AL0XGCBE6Z22M         1\n",
       "AMT5LF0TKY67C         2\n",
       "A2BY8EVXA3NRHD        3\n",
       "AWE6KR1ELIYQ3         4\n",
       "                  ...  \n",
       "A1MFBF49ZFMH2N    23313\n",
       "A36AF5I7D0VO8F    23314\n",
       "A35ZS7JT3G9B8     23315\n",
       "A3GC94SEKQI3QU    23316\n",
       "A185C12Y9XLYGY    23317\n",
       "Length: 23318, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ids = generate_unique_ids(reviews_df['reviewerID'])\n",
    "user_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B000B6AV7K        0\n",
       "B0143D7EE4        1\n",
       "B0105V2DEY        2\n",
       "B014EY21H2        3\n",
       "B005LUROIK        4\n",
       "              ...  \n",
       "B00A9R2P7A    38488\n",
       "B017HK485S    38489\n",
       "B008H7UKYY    38490\n",
       "B006K6PJTK    38491\n",
       "B01DUSBHZ0    38492\n",
       "Length: 38493, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_ids = generate_unique_ids(reviews_df['asin'])\n",
    "item_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split train test and validation by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews, validation_test_reviews = split_train_test_proportion(reviews_df, test_prop=0.4)\n",
    "validation_reviews, test_reviews = split_train_test_proportion(validation_test_reviews, test_prop=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113836"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(validation_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30728"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_reviews)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks. All users are in the train validation and test sets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_reviews['reviewerID']) == set(test_reviews['reviewerID']) ==  set(validation_reviews['reviewerID'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the train set and the validation set all have at least one item (same check as above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>val_size</th>\n",
       "      <th>test_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23318.000000</td>\n",
       "      <td>23318.000000</td>\n",
       "      <td>23318.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.881894</td>\n",
       "      <td>1.474397</td>\n",
       "      <td>1.317780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.529635</td>\n",
       "      <td>1.185903</td>\n",
       "      <td>1.091225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         train_size      val_size     test_size\n",
       "count  23318.000000  23318.000000  23318.000000\n",
       "mean       4.881894      1.474397      1.317780\n",
       "std        3.529635      1.185903      1.091225\n",
       "min        3.000000      1.000000      1.000000\n",
       "25%        3.000000      1.000000      1.000000\n",
       "50%        4.000000      1.000000      1.000000\n",
       "75%        5.000000      2.000000      1.000000\n",
       "max       61.000000     20.000000     20.000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    train_reviews.groupby('reviewerID').size().to_frame('train_size'),\n",
    "    validation_reviews.groupby('reviewerID').size().to_frame('val_size'),\n",
    "    test_reviews.groupby('reviewerID').size().to_frame('test_size')\n",
    "], axis=1).describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids.to_csv(DEST_FOLDER / 'users.txt')\n",
    "item_ids.to_csv(DEST_FOLDER / 'items.txt', header=['item_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14891</td>\n",
       "      <td>30409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19073</td>\n",
       "      <td>29339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21394</td>\n",
       "      <td>38246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22275</td>\n",
       "      <td>38246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6565</td>\n",
       "      <td>38246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178934</th>\n",
       "      <td>5195</td>\n",
       "      <td>6878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178935</th>\n",
       "      <td>418</td>\n",
       "      <td>7919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178937</th>\n",
       "      <td>11611</td>\n",
       "      <td>5762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178938</th>\n",
       "      <td>16539</td>\n",
       "      <td>5762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178939</th>\n",
       "      <td>13738</td>\n",
       "      <td>3855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113836 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user   item\n",
       "0       14891  30409\n",
       "4       19073  29339\n",
       "6       21394  38246\n",
       "10      22275  38246\n",
       "14       6565  38246\n",
       "...       ...    ...\n",
       "178934   5195   6878\n",
       "178935    418   7919\n",
       "178937  11611   5762\n",
       "178938  16539   5762\n",
       "178939  13738   3855\n",
       "\n",
       "[113836 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERIZED_COMMON_PARAMS = {\n",
    "    'uids': user_ids, \n",
    "    'product_ids': item_ids,\n",
    "    'user_id_column': 'user',\n",
    "    'product_ids_column': 'item',\n",
    "    'columns': ['user', 'item']\n",
    "}\n",
    "\n",
    "save_numerized(\n",
    "    train_reviews, \n",
    "    dest=DEST_FOLDER / 'train.txt',\n",
    "    **NUMERIZED_COMMON_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved validation data'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_numerized(\n",
    "    validation_reviews, \n",
    "    dest=DEST_FOLDER / 'validation.txt',\n",
    "    **NUMERIZED_COMMON_PARAMS\n",
    ")\n",
    "'Saved validation data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saved test data'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_numerized(\n",
    "    test_reviews, \n",
    "    dest=DEST_FOLDER / 'test.txt',\n",
    "    **NUMERIZED_COMMON_PARAMS\n",
    ")\n",
    "'Saved test data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file\n",
      "Initializing array (38493, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features:  24%|██▍       | 9.42k/38.5k [00:18<00:58, 499items/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m             res[idx, :] \u001b[39m=\u001b[39m value\n\u001b[1;32m     22\u001b[0m         \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m---> 25\u001b[0m image_features_array \u001b[39m=\u001b[39m copy_features(\n\u001b[1;32m     26\u001b[0m     item_ids\u001b[39m=\u001b[39;49mitem_ids, \n\u001b[1;32m     27\u001b[0m     features_file\u001b[39m=\u001b[39;49mCLIP_IMAGE_FEATURES\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m image_features_array\u001b[39m.\u001b[39mshape\n",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m, in \u001b[0;36mcopy_features\u001b[0;34m(item_ids, features_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mfull(array_shape,  fill_value\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m asin, idx \u001b[39min\u001b[39;00m tqdm(item_ids\u001b[39m.\u001b[39mitems(), \n\u001b[1;32m     14\u001b[0m         total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(item_ids), unit_scale\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, unit\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mitems\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     15\u001b[0m         desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCopying features\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     value \u001b[39m=\u001b[39m features[asin]\n\u001b[1;32m     18\u001b[0m     \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39misnan(value)\u001b[39m.\u001b[39msum() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFeature has NaN Values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m     res[idx, :] \u001b[39m=\u001b[39m value\n",
      "File \u001b[0;32m~/src/VBPR/.venv/lib/python3.8/site-packages/numpy/lib/npyio.py:242\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    233\u001b[0m     \u001b[39m# FIXME: This seems like it will copy strings around\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[39m#   more than is strictly necessary.  The zipfile\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[39m#   (or at least uncompress) the data\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[39m#   directly into the array memory.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     member \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_files:\n\u001b[1;32m    243\u001b[0m         member \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     \u001b[39melif\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def copy_features(\n",
    "        item_ids: pd.Series, \n",
    "        features_file: Path\n",
    "):\n",
    "    print('Opening file')\n",
    "    with np.load(features_file) as features:\n",
    "        some_embedding = next(iter(features.values()))\n",
    "        embedding_shape, = some_embedding.shape\n",
    "        array_shape = (len(item_ids),  embedding_shape)\n",
    "        print(f'Initializing array {array_shape}')\n",
    "        res = np.full(array_shape,  fill_value=np.nan)\n",
    "\n",
    "        for asin, idx in tqdm(item_ids.items(), \n",
    "                total=len(item_ids), unit_scale=True, unit='items', \n",
    "                desc='Copying features'):\n",
    "            value = features[asin]\n",
    "            \n",
    "            assert np.isnan(value).sum() == 0, \"Feature has NaN Values\"\n",
    "            \n",
    "            res[idx, :] = value\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "image_features_array = copy_features(\n",
    "    item_ids=item_ids, \n",
    "    features_file=CLIP_IMAGE_FEATURES\n",
    ")\n",
    "image_features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Clothing_Shoes_and_Jewelry/embed_image.npy: 225MiB\n"
     ]
    }
   ],
   "source": [
    "IMAGE_EMBED_DEST = DEST_FOLDER / 'embed_image.npy'\n",
    "np.save(IMAGE_EMBED_DEST, image_features_array)\n",
    "\n",
    "print(f'{str(IMAGE_EMBED_DEST)}: {IMAGE_EMBED_DEST.stat().st_size // 2**20}MiB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening file\n",
      "Initializing array (38493, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying features: 100%|██████████| 38.5k/38.5k [01:02<00:00, 615items/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38493, 768)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features_array = copy_features(\n",
    "    item_ids=item_ids, \n",
    "    features_file=CLIP_TEXT_FEATURES\n",
    ")\n",
    "text_features_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Clothing_Shoes_and_Jewelry/embed_text.npy: 225MiB\n"
     ]
    }
   ],
   "source": [
    "TEXT_EMBED_DEST = DEST_FOLDER / 'embed_text.npy'\n",
    "np.save(TEXT_EMBED_DEST, text_features_array)\n",
    "\n",
    "print(f'{str(TEXT_EMBED_DEST)}: {TEXT_EMBED_DEST.stat().st_size // 2**20}MiB')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/amazon/Clothing_Shoes_and_Jewelry_product_images')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df = amazon_dataset.products_df(DATASET)\n",
    "products_images_dir = amazon_dataset.product_images_dir(DATASET)\n",
    "products_images_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying images: 100%|██████████| 38.5k/38.5k [04:44<00:00, 135items/s, No images: 234]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def convert_image(src: str, dst: str):\n",
    "    min_white = np.array([235, 235, 235], np.uint8)\n",
    "    white = np.array([255, 255, 255], np.uint8)\n",
    "    img = cv2.imread(src)\n",
    "    \n",
    "    mask = 255 - cv2.inRange(img, min_white, white)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2BGRA)\n",
    "    res = cv2.bitwise_and(img, img, mask=mask)\n",
    "    cv2.imwrite(dst, res)\n",
    "\n",
    "def save_images(products_df: pd.DataFrame, item_ids: pd.Series, dest: Path):\n",
    "    products_by_asin = products_df.set_index('asin')\n",
    "    joined  = item_ids.to_frame('item_id').join(\n",
    "        products_by_asin, validate='one_to_one'\n",
    "    )\n",
    "    dest.mkdir(exist_ok=True)\n",
    "    \n",
    "    no_images = 0\n",
    "    \n",
    "    progress = tqdm(\n",
    "        joined.itertuples(), \n",
    "        desc='Copying images', \n",
    "        total=len(joined), \n",
    "        unit_scale=True, unit='items'\n",
    "    )\n",
    "    for row in progress:\n",
    "        if not isinstance(row.image_slug, list):\n",
    "            print('Not a list')\n",
    "            break\n",
    "        if len(row.image_slug) == 0:\n",
    "            no_images += 1\n",
    "            progress.set_postfix_str(f'No images: {no_images}', refresh=False)\n",
    "            continue\n",
    "        slug = row.image_slug[0]\n",
    "        src = products_images_dir / f\"{slug}.jpg\"\n",
    "        assert src.exists()\n",
    "        dst = dest / f'{row.item_id}.png'\n",
    "        convert_image(str(src), str(dst))\n",
    "\n",
    "#save_images(products_df, item_ids,  DEST_FOLDER / 'images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories_df = amazon_dataset.product_categories_df(DATASET)\n",
    "# products_df = amazon_dataset.products_df(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Calf Circumference up to 17 inches                                                                                                                                                                      0\n",
       "pull-on style makes getting dressed hassle-free                                                                                                                                                         1\n",
       "GELForm removable insole                                                                                                                                                                                2\n",
       "Material: 95% Polyester, 5% Spandex,high quality material, soft and comfortable.                                                                                                                        3\n",
       "size:US size,please choose the size according size chart,if you couldn't ensure the size,please email us your measurements:height,bust,waist and hip,then we will check which size fit you well.        4\n",
       "                                                                                                                                                                                                    ...  \n",
       "Package:Dress*1,style it with the self-belt which is sold separately                                                                                                                                35306\n",
       "SIZES: 30, 32, 34, 36, 38, 40                                                                                                                                                                       35307\n",
       "WIDE BRIM: measures 3.7\" in length, not only looks stylish, but also wide enough to shade uv rays effectively.                                                                                      35308\n",
       "Simple silhouette                                                                                                                                                                                   35309\n",
       "The item will be sent within 1 business day and standard shipping time is about 7-15 days                                                                                                           35310\n",
       "Length: 35311, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# categories_id = generate_unique_ids(categories_df['name'])\n",
    "# categories_id.to_csv(DEST_FOLDER / 'categories.txt', header=['category_id'])\n",
    "# categories_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_categories_matrix(\n",
    "        categories_df: pd.DataFrame, \n",
    "        products_df: pd.DataFrame, \n",
    "        item_ids: pd.Series, \n",
    "        categories_id: pd.Series\n",
    "    ):\n",
    "    MIN_SUPPORT = 0.01\n",
    "    MAX_SUPPORT = 0.9\n",
    "    \n",
    "    # Categories only with not too many or too few items\n",
    "    categories_support = categories_df['name'].value_counts() \n",
    "\n",
    "    allowed_categories_names = categories_support[1:8].index\n",
    "\n",
    "    print(\"How many allowed categories\")\n",
    "    print(len(allowed_categories_names))\n",
    "    print(allowed_categories_names)\n",
    "    \n",
    "    filtered_categories = categories_df.loc[\n",
    "        categories_df['name'].isin(allowed_categories_names)\n",
    "    ]\n",
    "\n",
    "    products_df = products_df.join(\n",
    "        item_ids.to_frame('item_id'), on='asin', validate='1:1')\n",
    "\n",
    "    res = filtered_categories.set_index('product_id').join(\n",
    "        products_df, validate='m:1')\n",
    "    res = res.reset_index(drop=True)\n",
    "    \n",
    "    # Check all categories are in categories_id\n",
    "    res = res.join(categories_id.to_frame('category_id'), on='name')\n",
    "    assert res['category_id'].isna().sum() == 0\n",
    "\n",
    "    items_with_no_category = set(item_ids) - set(res['item_id'].unique())\n",
    "    print(f\"items with no category: {len(items_with_no_category)}\")\n",
    "    \n",
    "    return products_df.loc[\n",
    "        products_df['asin'].isin(item_ids[items_with_no_category].index)\n",
    "    ]\n",
    "\n",
    "    return res[['item_id', 'category_id']]\n",
    "\n",
    "# categories_matrix = build_categories_matrix(\n",
    "#     categories_df, products_df, item_ids, categories_id\n",
    "# )\n",
    "#categories_matrix\n",
    "#categories_matrix.to_csv(DEST_FOLDER / 'categorical.txt', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c22d1444aa3f68a820bd00264b529de9aca8b813336c5d71bda95dadce90fbf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
